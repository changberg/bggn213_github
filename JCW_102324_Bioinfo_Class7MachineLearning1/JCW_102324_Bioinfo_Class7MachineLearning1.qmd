---
title: "JCW_102324_Bioinfo_Class7MachineLearning1"
author: "Janie Chang-Weinberg (A69037446)"
format: pdf
---

Before we get into clustering methods, let's make some sample data to cluster where we know what the answer should be.

To help with this, let's use the `rnorm()` function.

```{r}
hist(rnorm(150000, mean=c(-3,3)))

```

```{r}
x <- c(rnorm(30,mean=+3),rnorm(30,mean=-3))
y <- rev(x)

z <- cbind(x,y)
z
```

```{r}
plot(z)
```

## K-means clustering

The function in base R for clustering is `kmeans()`

```{r}
km <- kmeans(z,2)
km
```

> Q. Print out the cluster membership vector (ie, our main answer)

```{r}
km$cluster
```

```{r}
plot(z, col=c("red","blue"))
```

To plot with color by cluster result and add cluster centers:

```{r}
plot(z, col=km$cluster)
points(km$centers, col="blue", pch=42,cex=2)
```

> Q. Can you cluster our data in `z` into four clusters?

```{r}
km4 <- kmeans(z,centers=4)
plot(z, col=km4$cluster)
points(km4$centers, col="orange",pch=25)
```

## Hierarchical Clustering

The main function for hierarchical clustering in base R is called `hclust()`

Unlike `kmeans()`, you cannot just pass in the data as input. You first need a distance matrix from the data.

```{r}
d <- dist(z)
hc <- hclust(d)
hc
```

There is a specific hclust plot() method...

```{r}
plot(hc)
abline(h=9, col="red")
```

To get the main clustering result (ie, the membership vector), you can "cut" the cluster dendrogram at a given height. To perform this, use `cutree()`
```{r}
grps <- cutree(hc, h=9)
grps
```

## Principal Component Analysis
"Principal component analysis (PCA) is a well established "multivariate statistical technique" used to reduce the dimensionality of a complex data set to a more manageable number (typically 2D or 3D). This method is particularly useful for highlighting strong paterns and relationships in large datasets (i.e. revealing major similarities and diferences) that are otherwise hard to visualize. As we will see again and again in this course PCA is often used to make all sorts of bioinformatics data easy to explore and visualize." -ripped from webpage

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
dim(x)
```

```{r}
x
```

```{r}
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```

>Plot 1 (rainbow bar plot)

```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))
```

> Q. 3 (pls do this for a barplot)

```{r}
pairs(x, col=rainbow(10), pch=16)
```

## Principal Component Analysis can help organize data

The main function to do PCA in base R is `prcomp()`
The way the data are organized currently will not work, you must first transpose the data

```{r}
pca <- prcomp(t(x))
summary(pca)
```
Check what is inside `pca` that has been calculated

```{r}
attributes(pca)
```

```{r}
pca$x
```
To make our main results figure called a "PC plot" (or score/ordination/PC1vsPC2 plot)

```{r}
plot(pca$x[,1], pca$x[,2], 
     col=c("black", "red", "blue", "darkgreen"),
     pch=16,
     xlab="PC1 (67.4%)", ylab="PC2 (29%)")
```


```{r}
```

# variable loadings plot

can give us insight as to how the original variables (in this case the the foods) contribute to our PC axis

```{r}
pca$rotation
plot(pca$rotation)
```

